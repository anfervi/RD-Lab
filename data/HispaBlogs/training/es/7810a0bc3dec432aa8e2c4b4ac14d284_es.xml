<author id="7810a0bc3dec432aa8e2c4b4ac14d284" url="cesartomelopez.blogspot.com" feed="http://cesartomelopez.blogspot.com/feeds/posts/default" country="ES">
	<documents count="10">
		<document id="2c99d5fb33ab834e73812b1d52a0efa6" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/-TlkH_PSyWw/imponderable-el-primer-modelo-estandar.html">			<content><![CDATA[Cuando los humanos nos enfrentamos a algo complejo usamos analogías con otra cosa que nos es familiar. Estas analogías cambian con el tiempo y la evolución de la técnica y nuestra familiaridad con nuevos dispositivos. Así, por ejemplo, el funcionamiento del encéfalo humano a mediados del siglo XX se asemejaba a una centralita de teléfonos, mientras que hoy se suele comparar con un ordenador. En el siglo XVIII y a comienzos del siglo XIX las semejanzas se hacían con dispositivos mecánicos en general. Fenómenos tan novedosos como la electricidad o el estudio del calor encontraron pronto acomodo en la analogía con las conducciones de agua.Esta analogía para la electricidad puede trazarse hasta un momento preciso. En 1729 Stephen Gray descubrió que un hilo empapado conduce la electricidad, por lo que de ahí a asimilar el agente de la electricidad con agua corriendo por una tubería había un paso. Esta analogía se vería completada poco después por la comparación que hizo Benjamin Franklin entre las máquinas que se usaban para generar electricidad (en esta época poco más que cilindros y esferas de cristal que se frotaban, esto es, generadores electrostáticos rudimentarios) y las bombas impulsoras y entre las botellas de Leyden (los primeros condensadores) y los embalses.Para aquellos que aceptaron la versión de Robert Symmer(1759) de la teoría de Franklin en la que las cargas negativas eran tan reales como las positivas, en la electricidad participaban dos fluidos que, dado que los cuerpos cargados pesados pesaban tanto como los neutros, se asumía que tenían un peso no medible, esto es, eran imponderables. Se iniciaba así la construcción de un modelo, el modelo imponderable, que llegaría al siglo XX.Continúa leyendo en el Cuaderno de Cultura Científica]]></content>
		</document>
		<document id="3a30301582d38ed50abfb2d004adeed2" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/2P1WSkqMwko/gustave-le-bon-y-la-equivalencia.html">			<content><![CDATA[Si preguntamos a cualquier persona con una mediana formación científica sobre quién fue el primero en proponer la equivalencia entre masa y energía, nos respondería inmediatamente y sin vacilación que Albert Einstein. Puede que incluso nos diese la fecha (1905) y hasta la expresión matemática, E = mc2. Sin embargo, puede que no sea tan evidente. Y es que Gustave le Bon tuvo una magnífica intuición poco antes.Gustave le Bon nació en 1841 en Nogent-le-Rotrou (Francia) y se doctoró en medicina en 1866 en la Universidad de París. En la actualidad se le conoce por sus trabajos en psicología de grupos y en sociología (hay quien le considera uno de los fundadores de esta disciplina), pero también escribió sobre astronomía, física y cosmología. Según le Bon el universo material habría aparecido a partir del éter primordial e imponderable y terminaría regresando a este estado, en una serie de ciclos sin fin. Como parte de este concepto incluía la equivalencia de materia y energía.En 1896 le Bon anunció que había descubierto lo que llamó “luz negra”, un nuevo tipo de radiación invisible que él creía que estaba relacionada posiblemente con los rayos X y los rayos catódicos pero que era distinta a éstos. Sus afirmaciones atrajeron la atención de los físicos, fundamentalmente franceses, muchos de los cuales le dieron su apoyo en el descubrimiento así como a sus ideas sobre la materia, la radiación y el éter. Aunque al final la existencia de la “luz negra” fue descartada (no se pudieron reproducir sus resultados en condiciones controladas) durante un tiempo permitió que le Bon fuese una figura importante en la vida intelectual y científica francesa. En 1903 fue incluso nominado para el Nobel de física. Entre sus amigos y admiradores se encontraban científicos de primer nivel, incluyendo el químico Henri Ferdinand-Frédéric Moissan, el astrónomo Henri Alexandre Deslandres y los matemáticos Charles Émile Picard y Jules Henri Poincaré. Pero lo que nos interesa ahora es que en sus escritos sobre la “luz negra” estaba la primera descripción cualitativa de la equivalencia entre materia y energía.Le Bon expuso sus ideas más elaboradamente en “La evolución de la materia” (texto completo en francés, en inglés), un libro publicado, mire usted, en 1905. En él concluía que toda la materia es inestable y está degenerando, emitiendo constantemente radiación en forma de rayos X, radioactividad y “luz negra”. Las características de la materia serían epifenómenos que aparecerían durante el proceso de transformación en éter, informe e imponderable, del que había surgido. Según le Bon, la energía y la materia eran dos aspectos de la misma realidad, diferentes etapas en el gran proceso evolutivo que en un futuro lejano llevaría al universo a un estado puramente etéreo.Su principal argumento para la continua degradación de la materia en éter era la radioactividad, que él consideraba que era algo que toda la materia exhibía en mayor o menor grado. Pero le Bon, llevaba esta idea a sus últimas consecuencias. Si todos los elementos emiten radiación por la radiactividad, todos terminarían desapareciendo, por tanto la materia, en última instancia, no se explicaría en términos materiales sino etéreos. Paradójicamente, el estudio de la materia llevaba al inmaterialismo, algo muy bien recibido por determinados círculos intelectuales del fin de siglo francés.Le Bon tomó su versión de la evolución cósmica de la hipótesis nebular de Laplace, pero la revistió con el lenguaje de la entonces popularísima física del éter. Y, sin embargo, el éter no era para le Bon el último estadio final, ya que sugería que este fin del universo sería seguido de un renacimiento y posterior evolución, y que este proceso cíclico continuaría eternamente.Probablemente lo más interesante de su argumento es que afirmaba que todos los átomos contenían enormes cantidades de energía que se iría liberando conforme los átomos se desintegrasen, y que esta energía “intra-atómica”, como él la llamaba, era la fuente del calor solar y de todas las otras fuerzas del universo. Incluso empleaba cálculos (elementales) de energía cinética (T = mv2/2) para encontrar órdenes de magnitud de esas energías. Cuando Einstein se hizo famoso por su demostración de que la masa y la energía eran equivalentes según E = mc2 , le Bon reclamó parte del mérito para él. En 1922 escribió cartas a Einstein informándole de lo que él consideraba su prioridad en el descubrimiento de la reciprocidad de la masa y la energía. Ni que decir tiene que para esta época sus ideas estaban completamente desfasadas.Esta entrada es una participación de Experientia docet en la XLV Edición del Carnaval de la Física que acoge Cuantos y cuerdas.Gustavo me puso sobre la pista de le Bon en un comentario en esta entrada. Muchas gracias.]]></content>
		</document>
		<document id="9553adaae7bdd47023e8cd1970a0b307" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/3CYTtBnpe08/primer-cuasicristal-no-metalico.html">			<content><![CDATA[Un equipo de investigadores encabezados por Stefan Förster de la Universidad Martin Lutero en Halle-Wittenberg (Alemania) ha descubierto el primer cuasicristal en un óxido. El descubrimiento aparece publicado en Nature.Sólo se conoce un ejemplo de cuasicristal natural. Fue encontrado en 2009 por el investigador Paul Steinhardt, de la Universidad de Princeton, en las remotas montañas Koryak (en el extremo oriental de Siberia, al noreste de la península de Kamchatka), en una odisea digna de Indiana Jones. El cuasicristal de Steinhardt es una aleación de aluminio, hierro y cobre. Y es que es muy llamativo que todos los cuasicristales conocidos, desde que Dan Shechtman los descubriese a principios de los años ochenta del siglo pasado, sean aleaciones metálicas fabricadas todas, menos la natural, cuidadosamente en el laboratorio. Hasta ahora.El óxido en cuestión pertenece a la familia de las perovskitasy se trata de un titanato de bario (BaTiO3). Las perovskitas tienen una estructura cristalina lo suficientemente particular como para dar nombre a un grupo (en realidad es ortorrómbico o pseudocúbico; una mezcla de cubos y rombos, para entendernos) pero, eso sí, son manifiestamente cristalinas; es decir, presentan orden a corto y a largo. Son unos materiales muy estudiados por sus aplicaciones en superconductividad o en paneles solares, por ejemplo.Sin embargo, cuando Förster y sus colegas depositaron una capa fina de titanato de bario sobre una superficie de platino con simetría (1,1,1) que presenta ejes de simetría ternarios (es un sistema cúbico centrado en las caras), encontraron que en la interfase entre la perovskita y el platino aparecía una simetría dodecagonal, una de las llamadas simetrías prohibidas, para un espesor de 0,4 nm. Los datos fueron confirmados por una combinación de técnicas muy potentes: desde microscopía de efecto túnel para el rango corto a difracción de electrones para el largo.La simetría dodecagonal encontrada¿Cómo es esto posible?¿Cuál es el mecanismo?¿Ocurre algo parecido en otros materiales?¿Son los cuasicristales más comunes de lo que pensamos y se trata sólo de buscar el par compuesto-sustrato adecuado?¿Qué efecto podrá tener esto en la nanociencia de materiales? El que lo averigüe puede aspirar a publicar donde quiera, incluido Nature.Referencia:Förster S., Meinel K., Hammer R., Trautmann M. & Widdra W. (2013). Quasicrystalline structure formation in a classical crystalline thin-film system, Nature, 502 (7470) 215-218. DOI: 10.1038/nature12514Esta entrada es una participación de Experientia docet en la XXVIII Edición del Carnaval de Química que organiza Flagellum  ]]></content>
		</document>
		<document id="c419346cfe54bc1e14b11484659d5367" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/6LBaOr5W4GA/del-modelo-imponderable-la-hipotesis.html">			<content><![CDATA[En una anotación anterior presentábamos el modelo imponderable, el primer modelo estándar de la física. Hoy vamos a ver cómo evolucionó a lo largo del siglo XIX y cómo el afán por completarlo llevó a una física más allá del modelo estándar.El modelo imponderable, que se había ganado su lugar como el estándar alrededor de 1800, tenía dos virtudes principales. Por una parte explicaba inmediatamente la existencia de los fenómenos por la mera presencia del agente correspondiente y, por otro encajaba con la moda científica de la época: la cuantificación.En 1785, Charles Augustin Coulomb estableció, para satisfacción de los miembros de la Académie des Sciences de París, que las fuerzas entre los fluidos en la electricidad y en el magnetismo disminuían, como lo hacía la fuerza de la gravedad, con el cuadrado de la distancia entre los elementos que interactuaban.Pierre Simon de Laplace y su escuela mantuvieron durante mucho tiempo la ambición de cuantificar las fuerzas a distancia que se suponía que actuaban entre los elementos del fluido de calor (que ellos llamaban calórico) y entre las partículas de luz y la materia. Hoy puede parecernos absurdo por irreal pero Laplace y Jean Baptiste Biot se las arreglaron para, a partir de estas premisas, y en el marco del modelo imponderable, explicar con detalle la refracción, tanto simple como doble, la polarización y otros fenómenos ópticos.Tomando literalmente el concepto de calor como fluido conservado, Laplace creó una magnífica teoría de los procesos adiabáticos que resolvía el viejo problema de la escandalosa discrepancia entre los tratamientos teóricos y los resultados experimentales de las mediciones de la velocidad del sonido en el aire. Si bien no hacía uso de fuerzas a distancia, esta teoría adiabática asumía (y potenciaba la creencia en) la existencia del calórico.Continúa leyendo en el Cuaderno de Cultura Científica]]></content>
		</document>
		<document id="34b9b3f4009a253835b2fcd8f9713819" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/6zjPrBEH400/pensando-la-quimica-matematicamente.html">			<content><![CDATA[El conocimiento químico viene de antiguo. Hasta hace poco más de un siglo era un conocimiento puramente fenomenológico obtenido en la mayoría de los casos por ensayo y error. Démonos cuenta que la cuantificación en la química empieza a finales del siglo XVIII, con Lavoisier y el uso de la balanza, por lo que no cabría esperar la existencia ni de teoría química propiamente dicha, ni mucho menos, de una teoría de estructura matemática antes de esa fecha. Sin embargo, si nos paramos a definir qué es pensar matemáticamente, podemos encontrar ilustraciones de pensamiento matemático aplicado a la química desde la antigüedad. Y es que para pensar matemáticamente no hacen falta números. Veamos un ejemplo.La tabla de afinidades de GeoffroySiguiendo la filosofía cartesiana del XVII, varios filósofos naturales y matemáticos franceses desarrollaron la idea de un conocimiento químico racional y matematizado. Así, Bernard le Bovier de Fontenelle, el secretario a la sazón de la Académie des Sciences desde 1697, afirmaba en su introducción a la Histoire de l'Académie royale des sciences (1702) que:“las matemáticas no sólo han producido una infinitud de sus propias verdades, sino que también han producido en las mentes con bastante generalidad un hábito de exactitud y precisión incluso más precioso que todas estas verdades”.En ese mismo texto de Fontenelle sugería la idea de matematizar la química como se había hecho con la geometría (se refiere a la geometría analítica cartesiana), con objeto de poder hacer predicciones. El programa subyacente era legitimar la química como la parte teórica de la “vulgar farmacia” y como compañera respetable de los médicos y su arte.Un miembro de este grupo de filósofos naturales fue Etienne-François Geoffroy, el mismo médico, farmacéutico y químico. Geoffroy es conocido hoy día por la introducción en 1718 de la Table des differents rapports observés entre differentes substances (Tabla de las diferentes relaciones observadas entre diferentes sustancias). Geoffroy quería una tabla en la que uno pudiese ver “de un vistazo” las diferentes relaciones de las “principales materias con las que uno acostumbra a trabajar en química”. La tabla pronto se convirtió no sólo en una colección de información sino también en una herramienta para predecir sales y sus reacciones químicas.Continúa leyendo en el Cuaderno de Cultura Científica]]></content>
		</document>
		<document id="29827bac1c06faf89295328f31357720" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/bmGU7-kX3GU/bohr-100-anos-de-estados-estacionarios.html">			<content><![CDATA[En el pasado Passion for Knowledge - Quantum 13 di una charla naukas titulada "Bohr no fue el primero" que se puede ver aquí. En ella explicaba que Bohr no fue el primero en proponer un modelo cuántico del átomo como habitualmente se cree. Me basaba para afirmar esto en una investigación y recopilación de datos que ha durado casi un año y que se a materializado en un artículo titulado "Bohr: 100 años de estados estacionarios" que se ha publicado en la revista Anales de Química de la Real Sociedad Española de Química. Ahora este artículo está disponible gratuitamente en formato PDF en este enlace.Este trabajo no hubiese sido posible sin la ayuda inestimable de Bernardo Herradón (@quimicasociedad) y Daniel Torregrosa (@DaniEPAP), a los que reitero desde aquí mi agradecimiento.]]></content>
		</document>
		<document id="289877367d2e5d8e0ee6c3832d5aabef" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/BUulOjEK_7E/charla-en-quantum13-bohr-no-fue-el.html">			<content><![CDATA[El pasado día 4 tuve el privilegio de dar una charla Naukas titulada "Bohr no fue el primero" durante las jornadas Passion for Knowledege - Quantum13 en un marco incomparable, el teatro Victoria Eugenia de San Sebastián. Un reto ya que fui el primero tras una conferencia de Amand Lucas y, entre el público, premios Príncipe de Asturias, Nobel y profesores e investigadores de la UPV/EHU, el DIPC, el CFM, Tecnum, nanoGUNE y demás centros donostiarras (y de otros barrios de Bilbao).La charla es un resumen de un artículo que he escrito para los Anales de la Real Sociedad Española de Química que aparecerá presumiblemente en el próximo número, en el que se recogen los resultados de casi un año de investigación sobre el origen del modelo de Bohr, llegando a algunas conclusiones sorprendentes. Próximamente se publicará en el Cuaderno de Cultura Científica una versión en texto con los contenidos de la charla. De ambas publicaciones informaremos aquí.La charla (y todas las demás de Naukas) puede verse siguiendo este enlace.Esta entrada es una participación de Experientia docet en la XXVIII Edición del Carnaval de Química que organiza Flagellum]]></content>
		</document>
		<document id="3d98077d68a1c6bf8b8b21ff6b3d6086" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/c1f95CyrafE/primera-imagen-por-afm-de-un-enlace-de.html">			<content><![CDATA[¿Qué es un enlace químico? A estas alturas de la película debería ser una cuestión trivial. Pero no lo es tanto*. De hecho no existe una definición precisa, lo que abre las puertas a consideraciones varias en filosofía de la química. Por si no fuese suficientemente confuso, ahora, un grupo de investigadores encabezado por Jun Zhang, del Centro para la Nanociencia y la Tecnología de la Academia China de Ciencias, publica en Science las primeras imágenes de enlaces de hidrógeno. Estos enlaces se consideran en los libros de texto como poco menos que ficticios y se explican habitualmente como meras interacciones electromagnéticas. Sin embargo, los últimos resultados con difracción de rayos X indicaban que serían “auténticos” enlaces; el resultado de Zhang et al. viene a añadir leña al fuego.Los enlaces de hidrógeno son fundamentales para algunas de las moléculas y muchos de los procesos más importantes para la vida. Así, son los responsables de mantener unidas las dos hebras de la hélice del ADN y muchas enzimas realizan su función de catalizar reacciones haciendo uso de ellos. Una idea intuitiva de lo que es un enlace de hidrógeno es que es una fuerza atractiva entre átomos de distintas moléculas, uno de ellos un hidrógeno unido a un átomo muy electronegativo, con lo que deja al protón del núcleo de hidrógeno “sin el amparo de su electrón” y este protón se ve atraído por los electrones de un átomo electronegativo de otra molécula.Zhang et al. usaron un microscopio de fuerza atómica (AFM) con el método de no-contacto de Fischer para estudiar la 8-hidroxiquinolina. Esta molécula tiene la particularidad de que es plana pero los enlaces de hidrógeno que pueda formar quedan fuera de ese plano, lo que incrementa su visibilidad.Como podemos ver en la imagen, los enlaces de hidrógeno son visibles, más débiles que los “oficiales” covalentes de línea continua, pero visibles. Con esto volvemos al principio, ¿qué narices es un enlace químico?Más detalles en Chemistry Views*Por ejemplo, si hubiese que creer a la Wikipedia en español (cosa que, con honrosas excepciones, no es recomendable) un enlace químico es “un proceso”. Pero según la Wikipedia en inglés es “una atracción”, según la Wikipedia en francés “cualquier interacción atractiva”, y para la Wikipedia en alemán es “un fenómeno fisico-químico”. Referencia:Zhang J., Chen P., Yuan B., Ji W., Cheng Z. & Qiu X. Real-Space Identification of Intermolecular Bonding with Atomic Force Microscopy, Science, DOI: 10.1126/science.1242603Esta entrada es una participación de Experientia docet en la XXVIII Edición del Carnaval de Química que organiza Flagellum]]></content>
		</document>
		<document id="22e6eae0b0582d16a50b7dca17d8f9e7" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/dzw2qaHdT2s/los-putti-los-jesuitas-y-la-ciencia.html">			<content><![CDATA[Pedro Pablo Rubens llenaba sus lienzos con “putti”. Estos niños angelicales ayudaban a la gente a llegar al cielo, se sentaban en las cornisas de los edificios tocando instrumentos musicales, volaban desplegando pancartas, y llevaban los instrumentos de tortura a los mártires.Eran seres ágiles, hábiles, buenos por naturaleza y, en general, bastante listos y despiertos. Características todas ellas ideales para un ayudante de laboratorio. Por ello no es de extrañar que en los dibujos que realizó para Opticorum libri sex philosophis juxta ac mathematicis utiles, de François d'Aguilon (1613) Rubens optara por los putti para esta función. Así podemos verlos examinando el ojo del Cíclope, midiendo el Coloso de Rodas, aprendiendo las sutilezas de la visión binocular, demostrando la horóptera, usando el primer fotómetro, o demostrando cómo se realiza la proyección estereográfica. Los jesuitas, orden a la que pertenecía d'Aguilon, se dieron cuenta rápidamente de la utilidad de usar ángeles en los experimentos. Dos razones podrían explicar el uso frecuente de esta iconografía inusual. En primer lugar, la aparición de putti en un nuevo entorno, emergente y amenazante, como era la filosofía natural en el siglo XVII permitía hacerla más familiar y, de alguna forma, domesticarla, recordando que al final era Dios el que lo dirigía todo. Por decirlo gráficamente, si los angelotes tenían a bien jugar con barómetros, la investigación experimental de la atmósfera no podía de ninguna de las maneras amenazar ni al estado ni a la Iglesia. El uso de putti sería pues un mensaje tranquilizador hacia las autoridades.Continúa leyendo en el Cuaderno de Cultura Científica]]></content>
		</document>
		<document id="5690702e833d1768fbb7c2bd56ff0dc" url="http://feedproxy.google.com/~r/ExperientiaDocet/~3/Fu2cXv6mc4A/la-consciencia-no-tiene-un-area.html">			<content><![CDATA[Parcelación del encéfalo para el estudio del flujo de información | Monti et al (2013)El que la consciencia es un un fenómeno emergente relacionado con la comunicación entre distintas áreas del encéfalo, en vez de estar centrado en una sola de ellas, se hace cada vez más evidente. Ahora un grupo de investigadores encabezado por Martin Monti de la Universidad de California en Los Ángeles (Estados Unidos), añade otra gotita al vaso. Ha usado resonancia magnética funcional (fMRI) para estudiar el encéfalo de voluntarios en el momento de quedar inconscientes y publicado sus resultados en PloS Computational Biology.Un fenómeno emergente es aquel, habitualmente complejo, que surge de la interacción de sistemas de muchos componentes cada uno de los cuales tiene un funcionamiento muy sencillo. Ejemplos son los movimientos de las bandadas de estorninos (unidad: estornino) o bancos de peces (unidad: pez), el tráfico en una ciudad (unidad: vehículo) o la imagen que estás viendo en pantalla (unidad: píxel).Monti et al usaron fMRI para estudiar el flujo de información en los encéfalos de 12 voluntarios sanos mientras éstos perdían la consciencia al ser anestesiados con propofol. La edad de los sujetos oscilaba entre los 18 y los 31 años, había igual número de mujeres y varones y el procedimiento se llevó a cabo en el Hospital Universitario de Lieja (Bélgica).Los encéfalos de los sujetos fueron estudiados usando teoría de grafos para dilucidar sus propiedades de red, la misma teoría que se emplea para estudiar otros fenómenos complejos en los que intervienen nodos: los grupos sociales, el tráfico aéreo o la información en Internet, por ejemplo.El resultado más significativo del estudio es que cuando perdemos la consciencia la comunicación entre las áreas del cerebro deja de ser eficiente, como si de repente cada área del encéfalo se alejase de las demás, dificultando de esta forma que la información fluyese de una a otra.Estos datos reforzarían la idea de que la consciencia no reside en un lugar en concreto de nuestro encéfalo sino que emergedel modo en el que miles de millones de neuronas se comunican entre sí.Este y otros hallazgos recientes los comentaremos durante Status Quo el próximo 5 de noviembre en San Sebastián (habrá streaming).Referencia:Monti M.M., Lutkenhoff E.S., Rubinov M., Boveroux P., Vanhaudenhuyse A., Gosseries O., Bruno M.A., Noirhomme Q., Boly M. & Laureys S. & (2013). Dynamic Change of Global and Local Information Processing in Propofol-Induced Loss and Recovery of Consciousness, PLoS Computational Biology, 9 (10) e1003271. DOI: 10.1371/journal.pcbi.1003271.s003]]></content>
		</document>
	</documents>
</author>